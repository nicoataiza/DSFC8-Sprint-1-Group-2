{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Algorithms - K-Means Demo and Exercise\n",
    "\n",
    "Now that you have been introduced to clustering algorithms, we will demonstrate how it is done in Python and provide a few practice exercises.\n",
    "\n",
    "## Introduction\n",
    "The k-means algorithm searches for a pre-determined number of clusters within an unlabeled multidimensional dataset. It accomplishes this using a simple conception of what the optimal clustering looks like:\n",
    "- The \"cluster center\" is the arithmetic mean of all the points belonging to the cluster.\n",
    "- Each point is closer to its own cluster center than to other cluster centers.\n",
    "\n",
    "Those two assumptions are the basis of the k-means model. \n",
    "\n",
    "We will soon dive into exactly how the algorithm reaches this solution, but for now let's take a look at a simple dataset and see the k-means result.\n",
    "\n",
    "### Generate the dataset and plot for visual inspection\n",
    "We can probably pick out the clusters visually if we plot them in the feature space. In this example, we will generate a dataset with two features and 300 samples. Once it's generated, we will plot the dataset to visually inspect the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y_true = make_blobs(n_samples=300, centers=4,\n",
    "                       cluster_std=0.60, random_state=0)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster with k-means and plot again for validation\n",
    "Based on visual inspection, the appropriate number of clusters appears to be 4. We will fit the `KMeans` model from `sklearn.cluster` to our feature data and then plot the predicted clusters and their centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Tuning\n",
    "In order to determine the optimal number of clusters, we can try different values and measure the quality of our clusters with each iteration and select the model with the highest quality.\n",
    "\n",
    "#### Evaluation Metrics\n",
    "We discussed a few measures of cluster quality we can use to assess our clusters in a more objective way, including:\n",
    "\n",
    "- Within clusters:\n",
    "    - __Inertia__: Measures how close objects are to their cluster centroid\n",
    "    - __Cohesion__: Measures how close objects are to other members in their cluster\n",
    "\n",
    "- Between clusters\n",
    "    - __Separation__: Measures how distinct clusters are from one another\n",
    "\n",
    "- A combination of measurements:\n",
    "    - __Silhouette__: Based on a combination of Cohesion and Separation\n",
    "    \n",
    "We will access some metrics from the model directly, and for others we will use `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Inertia: \" + str(kmeans.inertia_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you want is a model with a low intertia AND low number of clusters, but that is a tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "s_score = silhouette_score(X, y_kmeans)\n",
    "print(\"Silhouette: \" + str(s_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For silhoutte score, we want a value that's closer to one than negative one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning\n",
    "We can try different values for the `n_clusters` parameter and measure the quality with each iteration to determine the optimal value and confirm our visual assessment.\n",
    "\n",
    "It's helpful to plot the results of each iteration to see the impact on each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inertia = []\n",
    "sil = []\n",
    "\n",
    "# changing the number of clusters \n",
    "for k in range(2,11):\n",
    "    \n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(X)\n",
    "    y_pred = km.predict(X)\n",
    "    \n",
    "    inertia.append((k, km.inertia_))\n",
    "    sil.append((k, silhouette_score(X, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "# Plotting Elbow Curve\n",
    "x_iner = [x[0] for x in inertia]\n",
    "y_iner  = [x[1] for x in inertia]\n",
    "ax[0].plot(x_iner, y_iner)\n",
    "ax[0].set_xlabel('Number of Clusters')\n",
    "ax[0].set_ylabel('Intertia')\n",
    "ax[0].set_title(\"Inertia Score - AKA. 'Elbow Curve'\")\n",
    "\n",
    "# Plotting Silhouetter Score\n",
    "x_sil = [x[0] for x in sil]\n",
    "y_sil  = [x[1] for x in sil]\n",
    "ax[1].plot(x_sil, y_sil)\n",
    "ax[1].set_xlabel('Number of Clusters')\n",
    "ax[1].set_ylabel('Silhouetter Score')\n",
    "ax[1].set_title('Silhouetter Score Curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final assessment\n",
    "The silouette score confirms our visual evaluation that the optimal number of clusters for this particular dataset appears to be 4, which makes sense since it was generated as such at the start of the demonstration.\n",
    "\n",
    "It's important to understand that the intertia score will continue to improve as we break the data down into smaller and smaller clusters. However, there is an obvious point at Number of Clusters equal to 4 where the improvement in the intertia metric starts to level off. This is known as the _elbow_ and is the optimal point from the intertia perspective.\n",
    "\n",
    "Finally, we can take a look at each prediction for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "y_pred = kmeans.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations\n",
    "The fundamental model assumptions of k-means (points will be closer to their own cluster center than to others) means that the algorithm will often be ineffective if the clusters have complicated geometries.\n",
    "\n",
    "In particular, the boundaries between k-means clusters will always be linear, which means that it will fail for more complicated boundaries. Consider the following data, along with the cluster labels found by the typical k-means approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(200, noise=.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels = KMeans(2, random_state=0).fit_predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels,\n",
    "            s=50, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular Use Case: Image Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting application of clustering is in color compression within images. For example, imagine you have an image with millions of colors. In most images, a large number of the colors will be unused, and many of the pixels in the image will have similar or even identical colors.\n",
    "\n",
    "#### Context\n",
    "Images contain many different colours in each pixel, which can be stored as different combinations of the colours red, green and blue (AKA. RGB values). RGB values are measured as integers between 0 and 255, which means there are a total of `255 * 255 * 255` or 16 million possible colours. Ultimately, the size of the image will depend in part on the number of different colours present in the image. \n",
    "\n",
    "#### The goal\n",
    "If we reduce the number of colours in the image, less information will be stored and thus the image will be smaller. We may lose some information in the image, but as long as we can still tell what the image is, that's okay.\n",
    "\n",
    "#### The solution\n",
    "We can use KMeans clustering to group similar colours, and then replace all the colours with the colour at their cluster's centre, thus compressing the image while also preserving it.\n",
    "\n",
    "#### The process\n",
    "\n",
    "__Step 1__: Import and plot the original image\n",
    "- We will use a sample image from `sklearn.datasets` to demonstrate.\n",
    "- We will plot the image and then vectorize it into a matrix of pixels and RGB (Red, Green, Blue) values for each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "fig = plt.figure(figsize=(24,18))\n",
    "ax1 = fig.add_subplot(2,2,1)\n",
    "ax1.axis('off')\n",
    "ax1.imshow(china, aspect='auto');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2:__ Inspect matrix of pixels (observations) and their Red, Green, and Blue values (features).\n",
    "\n",
    "We will show the first few pixels to get an idea of what the matrix looks like.\n",
    "- It has 427 rows, 640 columns, and three values for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "china.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "china[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Reshaping and scaling the data.\n",
    "- reshape the data to `[n_samples x n_features]`\n",
    "    - Each row will be a pixel\n",
    "    - Each column will be the red, green, or blue value\n",
    "- rescale the RGB values so that they lie between 0 and 1\n",
    "    - Divide by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = china / 255.0 # use 0...1 scale\n",
    "data = data.reshape(427 * 640, 3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Plot the data in the feature space.\n",
    "\n",
    "Once we have transformed and scaled the data, we can plot it. Since we have three features and we are plotting in 2D, we will need to examine two plots.\n",
    "\n",
    "We can show all the pixels in the photo based on the extent to which they express each feature (Red, Green or Blue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_pixels(data, title, colors=None, N=10000):\n",
    "    if colors is None:\n",
    "        colors = data\n",
    "    \n",
    "    # choose a random subset\n",
    "    rng = np.random.RandomState(0)\n",
    "    i = rng.permutation(data.shape[0])[:N]\n",
    "    colors = colors[i]\n",
    "    R, G, B = data[i].T\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax[0].scatter(R, G, color=colors, marker='.')\n",
    "    ax[0].set(xlabel='Red', ylabel='Green', xlim=(0, 1), ylim=(0, 1))\n",
    "\n",
    "    ax[1].scatter(R, B, color=colors, marker='.')\n",
    "    ax[1].set(xlabel='Red', ylabel='Blue', xlim=(0, 1), ylim=(0, 1))\n",
    "\n",
    "    fig.suptitle(title, size=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pixels(data, title='Input color space: 16 million possible colors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "255 * 255 * 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Reducing the number of colours down to 16 using `KMeans` and plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=16)\n",
    "kmeans.fit(data)\n",
    "new_colors = kmeans.cluster_centers_[kmeans.predict(data)]\n",
    "\n",
    "#Plotting the results\n",
    "plot_pixels(data, colors=new_colors,\n",
    "            title=\"Reduced color space: 16 colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6:__ Compare results before and after compression\n",
    "\n",
    "Plotting these new colors in the image space rather than the pixel space shows us the effect of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "china_recolored = new_colors.reshape(china.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 6),\n",
    "                       subplot_kw=dict(xticks=[], yticks=[]))\n",
    "fig.subplots_adjust(wspace=0.05)\n",
    "ax[0].imshow(china)\n",
    "ax[0].set_title('Original Image', size=16)\n",
    "ax[1].imshow(china_recolored)\n",
    "ax[1].set_title('16-color Image', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "# Group Exercise\n",
    "We will practice appling KMeans clustering to another use-case and dataset.\n",
    "\n",
    "Let's use the `2016-2019-voter-data.csv` and try to cluster the different municipalities based on any features available in or derived from the dataset. We want to identify distinct groups of municipalities so we can design a better program for voter education in the country.\n",
    "\n",
    "#### The solution\n",
    "We can use KMeans clustering to group similar municipalities. The optimal number of groups will be determined by trying different values and measuring the quality of the groups based on the silhouette score.\n",
    "\n",
    "#### The process\n",
    "__Step 1__: Import the dataset _(done for you)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/2016-2019-voter-data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2__: Select the columns you want to use for clustering and do feature scaling using `Normalizer` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Select features for clustering\n",
    "feature_cols = []\n",
    "X = df[feature_cols]\n",
    "\n",
    "# Feature scaling\n",
    "X=Normalizer().fit_transform(X.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3:__ Train initial KMeans model with `n_clusters` = 5, and print out the `inertia` and `silhouette_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Insert code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Inertia: \" + str(kmeans.inertia_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "s_score = silhouette_score(X, y_kmeans)\n",
    "print(\"Silhouette: \" + str(s_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4:__ Tune the model by trying different values for `n_clusters` between 3-20 and plot the results to determine the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try fitting w/ different number of clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "\n",
    "# Plotting Elbow Curve\n",
    "\n",
    "# Plotting Silhouetter Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5:__ Apply the optimal number of clusters and append cluster labels to your original df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Complete code here\n",
    "kmeans = \n",
    "kmeans.fit(X)\n",
    "labels = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cluster Labels'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "__Step 6:__ Inspect which municipalities were assigned to each group when we applied the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
